# Model Agent Comparison

A systematic evaluation framework for comparing AI model performance across different agentic workflows and tasks.

## Overview

This repository contains comparative analyses of various AI models executing structured workflows, enabling objective assessment of model capabilities in autonomous task completion.

## Structure

```
workflows/
├── scoping/           # Smart contract audit scoping workflows
│   ├── claude-4-sonnet/
│   └── gpt-5-preview/
└── [additional workflows]
```

## Methodology

Each workflow execution includes:
- Chat logs with complete interaction history
- Generated deliverables and artifacts
- State tracking and progress documentation
- Comparative performance metrics

## Models Evaluated

- Claude 4 Sonnet
- GPT-5 Preview
- [Additional models as evaluated]

---

*Professional AI model benchmarking for agentic task execution.*
